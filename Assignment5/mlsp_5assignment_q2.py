# -*- coding: utf-8 -*-
"""mlsp_5assignment_q2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bekKv5soRiZGYGcAvw-Xxu8GmrQaV5WE
"""

!pip install mnist

import tensorflow as tf
from tensorflow import keras
import numpy as np
import mnist

from tensorflow.examples.tutorials import mnist

mnist_data = mnist.input_data.read_data_sets('/tmp')
train_data = mnist_data.train
test_data = mnist_data.test

train_data.images.shape

test_data.images.shape

type(train_data.labels)

# images = mnist.train_images()
# labels = mnist.train_labels()

images = train_data.images
labels = train_data.labels
test_images = test_data.images
test_labeks = test_data.labels

# test_images = mnist.test_images()
# test_labels = mnist.test_labels()
images = images.reshape(55000,28,28,1)
from tensorflow.keras.layers import Dense, Dropout, Flatten
input_shape=(28,28,1)
num_classes = 10
model = keras.Sequential()
model.add(keras.layers.Conv2D(128, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(256, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))
model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

model.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), 
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

tr_loss=[]
val_loss=[]
test_acc=[]
test_loss=[]
for i in range(20):
  cnn_train = model.fit(images, labels, epochs=1,validation_split=0.10,batch_size = 200)
  tr_loss.append(cnn_train.history['loss'])
  val_loss.append(cnn_train.history['val_loss'])
  l,acc = model.evaluate(test_images.reshape(10000,28,28,1),test_labeks)
  test_acc.append(acc)
  test_loss.append(l)

import matplotlib.pyplot as plt
plt.plot(tr_loss,label ="train loss")
plt.plot(val_loss,label =" val loss")
plt.plot(test_acc,label ="test_accuracy")
plt.plot(test_loss,label="test_loss")
plt.legend()
plt.show()

loss, acc = model.evaluate(test_images.reshape(10000,28,28,1),test_labeks)

print(acc)



"""Using maxpool and 2 filters"""

input_shape=(28,28,1)
num_classes = 10
model2 = keras.Sequential()
model2.add(keras.layers.Conv2D(128, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model2.add(keras.layers.Conv2D(64, (5, 5), activation='relu'))
model2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
model2.add(Dropout(0.25))
model2.add(Flatten())
model2.add(Dense(128, activation='relu'))
model2.add(Dropout(0.2))
model2.add(Dense(256, activation='relu'))
model2.add(Dropout(0.2))
model2.add(Dense(512, activation='relu'))
model2.add(Dropout(0.2))
model2.add(Dense(num_classes, activation='softmax'))
model2.compile(loss=keras.losses.sparse_categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

# print(model2.summary())
tr_loss=[]
val_loss=[]
test_acc=[]
for i in range(20):
  cnn_maxpool_train = model2.fit(images, labels, epochs=1,validation_split=0.10,batch_size = 200)
  tr_loss.append(cnn_maxpool_train.history['loss'])
  val_loss.append(cnn_maxpool_train.history['val_loss'])
  _,acc = model.evaluate(test_images.reshape(10000,28,28,1),test_labeks)
  test_acc.append(acc)
# cnn_maxpool_train = model2.fit(images, labels, epochs=20,validation_split=0.10)

import matplotlib.pyplot as plt
plt.plot(tr_loss,label ="train loss")
plt.plot(val_loss,label =" val loss")
plt.plot(test_acc,label ="test_accuracy")
plt.legend()
plt.show()

loss, acc = model2.evaluate(test_images.reshape(10000,28,28,1),test_labeks)
print(acc)

type(cnn_maxpool_train.history['loss'])

